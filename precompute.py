#!/usr/bin/env python3
"""
SKEP DataAnalysis - Precompute Script
=====================================

Raw ë°ì´í„°ë¥¼ ì‚¬ì „ ì²˜ë¦¬í•˜ì—¬ ìºì‹œ íŒŒì¼ë¡œ ì €ì¥
ëŒ€ì‹œë³´ë“œì—ì„œ ë¹ ë¥´ê²Œ ë¡œë“œí•˜ì—¬ ë¶„ì„ ê²°ê³¼ í‘œì‹œ

ì‚¬ìš©ë²•:
    python precompute.py Datafile/Rawdata/Yongin_Cluster_20250909
    python precompute.py <data_folder>

ë°ì´í„° í˜•ì‹:
    - T31_*.csv: ì¥ë¹„ ëª¨ë‹ˆí„°ë§ (Type 31)
    - T41_*.csv: ì‘ì—…ì í—¬ë©§ (Type 41)  
    - TMobile_*.csv: ìŠ¤ë§ˆíŠ¸í° ìœ ë™ì¸êµ¬ (Flow)
"""

import os
import sys
import json
import glob
import hashlib
import time
from pathlib import Path
from datetime import datetime, timedelta
from dataclasses import dataclass, asdict
from typing import Dict, List, Optional, Tuple

import pandas as pd
import numpy as np


# ============================================================================
# ìƒìˆ˜ ì •ì˜
# ============================================================================

# ë°ì´í„° íƒ€ì…
DATA_TYPE_T31 = 31
DATA_TYPE_T41 = 41
DATA_TYPE_FLOW = 10  # TMobile

# ê¸°ë³¸ ì»¬ëŸ¼ëª…
COLUMN_NAMES = ['sward_id', 'mac', 'type', 'rssi', 'time']


# ============================================================================
# ì„¤ì •
# ============================================================================

@dataclass
class PrecomputeConfig:
    """ì‚¬ì „ ê³„ì‚° ì„¤ì •"""
    # ì‹œê°„ ë‹¨ìœ„ (ì´ˆ)
    time_unit_seconds: int = 10
    
    # ì²´ë¥˜ì‹œê°„ í•„í„°ë§
    min_dwell_time_minutes: int = 30
    
    # T41 ë¶„ì„ ì„¤ì •
    occupancy_time_unit_minutes: int = 10
    
    # íˆíŠ¸ë§µ ì„¤ì •
    heatmap_time_slot_minutes: int = 10
    
    def to_dict(self) -> dict:
        return asdict(self)
    
    def get_hash(self) -> str:
        config_str = json.dumps(self.to_dict(), sort_keys=True)
        return hashlib.md5(config_str.encode()).hexdigest()[:8]


# ============================================================================
# ë©”ì¸ Precomputer í´ë˜ìŠ¤
# ============================================================================

class DataAnalysisPrecomputer:
    """SKEP DataAnalysis ì‚¬ì „ ê³„ì‚° í´ë˜ìŠ¤"""
    
    def __init__(self, data_folder: str, sward_config_path: str = None):
        self.data_folder = Path(data_folder)
        self.cache_folder = self.data_folder / "cache"
        self.config = PrecomputeConfig()
        
        # S-Ward ì„¤ì • íŒŒì¼ ê²½ë¡œ - ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©
        if sward_config_path:
            self.sward_config_path = Path(sward_config_path)
        else:
            # ê¸°ë³¸ ê²½ë¡œ: ì´ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ê¸°ì¤€ìœ¼ë¡œ ìƒëŒ€ ê²½ë¡œ ê³„ì‚°
            script_dir = Path(__file__).parent.resolve()
            self.sward_config_path = script_dir / "Datafile" / "sward_configuration.csv"
        
        # ë°ì´í„° ì €ì¥
        self.t31_df: Optional[pd.DataFrame] = None
        self.t41_df: Optional[pd.DataFrame] = None
        self.flow_df: Optional[pd.DataFrame] = None
        self.sward_config: Optional[pd.DataFrame] = None
        
    def run(self):
        """ì „ì²´ ì‚¬ì „ ê³„ì‚° ì‹¤í–‰"""
        start_time = time.time()
        
        print("=" * 60)
        print("ğŸš€ SKEP DataAnalysis Precompute ì‹œì‘")
        print("=" * 60)
        print(f"ğŸ“‚ ë°ì´í„° í´ë”: {self.data_folder}")
        print(f"ğŸ’¾ ìºì‹œ í´ë”: {self.cache_folder}")
        print()
        
        # 1. ë°ì´í„° ë¡œë“œ
        print("ğŸ“‚ [1/11] Raw ë°ì´í„° ë¡œë“œ ì¤‘...")
        self._load_raw_data()
        
        # 2. S-Ward ì„¤ì • ë¡œë“œ
        print("ğŸ—ºï¸ [2/11] S-Ward ì„¤ì • ë¡œë“œ ì¤‘...")
        self._load_sward_config()
        
        # 3. T31 ë¶„ì„ (ì¥ë¹„ ëª¨ë‹ˆí„°ë§)
        if self.t31_df is not None and len(self.t31_df) > 0:
            print("ğŸ”§ [3/11] T31 (ì¥ë¹„) ë¶„ì„ ì¤‘...")
            t31_results = self._compute_t31_analysis()
        else:
            print("â­ï¸ [3/11] T31 ë°ì´í„° ì—†ìŒ - ê±´ë„ˆëœ€")
            t31_results = {}
        
        # 4. T41 ë¶„ì„ (ì‘ì—…ì í—¬ë©§)
        if self.t41_df is not None and len(self.t41_df) > 0:
            print("ğŸ‘· [4/11] T41 (ì‘ì—…ì) ë¶„ì„ ì¤‘...")
            t41_results = self._compute_t41_analysis()
        else:
            print("â­ï¸ [4/11] T41 ë°ì´í„° ì—†ìŒ - ê±´ë„ˆëœ€")
            t41_results = {}
        
        # 5. Flow ë¶„ì„ (ìŠ¤ë§ˆíŠ¸í°)
        if self.flow_df is not None and len(self.flow_df) > 0:
            print("ğŸ“± [5/11] Flow (ìŠ¤ë§ˆíŠ¸í°) ë¶„ì„ ì¤‘...")
            flow_results = self._compute_flow_analysis()
        else:
            print("â­ï¸ [5/11] Flow ë°ì´í„° ì—†ìŒ - ê±´ë„ˆëœ€")
            flow_results = {}
        
        # 6. í†µí•© ë¶„ì„
        print("ğŸ“Š [6/11] í†µí•© ë¶„ì„ ì¤‘...")
        combined_results = self._compute_combined_analysis()
        
        # 7. íˆíŠ¸ë§µ ë°ì´í„°
        print("ğŸ—ºï¸ [7/11] íˆíŠ¸ë§µ ë°ì´í„° ìƒì„± ì¤‘...")
        heatmap_results = self._compute_heatmap_data()
        
        # 8. Dashboard Overview ë°ì´í„°
        print("ğŸ“Š [8/11] Dashboard Overview ë°ì´í„° ìƒì„± ì¤‘...")
        dashboard_results = self._compute_dashboard_data()
        
        # 9. AI Insights ìƒì„±
        print("ğŸ¤– [9/11] AI Insights ìƒì„± ì¤‘...")
        ai_insights = self._generate_ai_insights(t31_results, t41_results, flow_results)
        
        # 10. ìœ„ì¹˜ íˆíŠ¸ë§µ ì´ë¯¸ì§€ ìƒì„±
        print("ğŸ—ºï¸ [10/11] ì‘ì—…ì ìœ„ì¹˜ íˆíŠ¸ë§µ ìƒì„± ì¤‘...")
        self._generate_location_heatmaps()
        
        # 11. ìºì‹œ ì €ì¥
        print("ğŸ’¾ [11/11] ìºì‹œ ì €ì¥ ì¤‘...")
        self._save_cache(
            t31_results=t31_results,
            t41_results=t41_results,
            flow_results=flow_results,
            combined_results=combined_results,
            heatmap_results=heatmap_results,
            dashboard_results=dashboard_results,
            ai_insights=ai_insights
        )
        
        elapsed = time.time() - start_time
        print()
        print("=" * 60)
        print(f"âœ… ì‚¬ì „ ê³„ì‚° ì™„ë£Œ! ({elapsed:.1f}ì´ˆ)")
        print("=" * 60)
        
        self._print_summary()
    
    def _load_raw_data(self):
        """Raw ë°ì´í„° íŒŒì¼ ë¡œë“œ"""
        
        # T31 íŒŒì¼ ì°¾ê¸°
        t31_files = list(self.data_folder.glob("T31_*.csv"))
        if t31_files:
            print(f"  ğŸ“„ T31 íŒŒì¼: {len(t31_files)}ê°œ")
            dfs = []
            for f in t31_files:
                df = pd.read_csv(f, names=COLUMN_NAMES)
                df['source_file'] = f.name
                dfs.append(df)
            self.t31_df = pd.concat(dfs, ignore_index=True)
            self.t31_df['time'] = pd.to_datetime(self.t31_df['time'])
            print(f"  âœ… T31: {len(self.t31_df):,} rows ë¡œë“œ")
        
        # T41 íŒŒì¼ ì°¾ê¸°
        t41_files = list(self.data_folder.glob("T41_*.csv"))
        if t41_files:
            print(f"  ğŸ“„ T41 íŒŒì¼: {len(t41_files)}ê°œ")
            dfs = []
            for f in t41_files:
                # ëŒ€ìš©ëŸ‰ íŒŒì¼ì€ ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
                file_size_mb = f.stat().st_size / (1024 * 1024)
                if file_size_mb > 100:
                    print(f"    â³ ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ ì¤‘: {f.name} ({file_size_mb:.1f}MB)")
                    chunks = []
                    for chunk in pd.read_csv(f, names=COLUMN_NAMES, chunksize=100000):
                        chunks.append(chunk)
                    df = pd.concat(chunks, ignore_index=True)
                else:
                    df = pd.read_csv(f, names=COLUMN_NAMES)
                df['source_file'] = f.name
                dfs.append(df)
            self.t41_df = pd.concat(dfs, ignore_index=True)
            self.t41_df['time'] = pd.to_datetime(self.t41_df['time'])
            print(f"  âœ… T41: {len(self.t41_df):,} rows ë¡œë“œ")
        
        # TMobile (Flow) íŒŒì¼ ì°¾ê¸°
        flow_files = list(self.data_folder.glob("TMobile_*.csv"))
        if flow_files:
            print(f"  ğŸ“„ Flow íŒŒì¼: {len(flow_files)}ê°œ")
            dfs = []
            for f in flow_files:
                file_size_mb = f.stat().st_size / (1024 * 1024)
                if file_size_mb > 100:
                    print(f"    â³ ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ ì¤‘: {f.name} ({file_size_mb:.1f}MB)")
                    chunks = []
                    for chunk in pd.read_csv(f, names=COLUMN_NAMES, chunksize=100000):
                        chunks.append(chunk)
                    df = pd.concat(chunks, ignore_index=True)
                else:
                    df = pd.read_csv(f, names=COLUMN_NAMES)
                df['source_file'] = f.name
                dfs.append(df)
            self.flow_df = pd.concat(dfs, ignore_index=True)
            self.flow_df['time'] = pd.to_datetime(self.flow_df['time'])
            print(f"  âœ… Flow: {len(self.flow_df):,} rows ë¡œë“œ")
    
    def _load_sward_config(self):
        """S-Ward ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        if self.sward_config_path.exists():
            self.sward_config = pd.read_csv(self.sward_config_path)
            print(f"  âœ… S-Ward ì„¤ì •: {len(self.sward_config)} ê°œ ë¡œë“œ")
            
            # building, level ëª©ë¡
            buildings = self.sward_config['building'].unique().tolist()
            print(f"  ğŸ“ Buildings: {buildings}")
        else:
            print(f"  âš ï¸ S-Ward ì„¤ì • íŒŒì¼ ì—†ìŒ: {self.sward_config_path}")
    
    def _add_time_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """ì‹œê°„ ê´€ë ¨ íŠ¹ì„± ì¶”ê°€"""
        df = df.copy()
        
        # ë‚ ì§œ/ì‹œê°„ íŠ¹ì„±
        df['date'] = df['time'].dt.date.astype(str)
        df['hour'] = df['time'].dt.hour
        df['minute'] = df['time'].dt.minute
        
        # time_index (10ì´ˆ ë‹¨ìœ„)
        time_normalized = df['time'].dt.normalize()
        df['time_index'] = ((df['time'] - time_normalized) / pd.Timedelta(seconds=self.config.time_unit_seconds)).astype(int)
        
        # ë¶„ ë‹¨ìœ„ bin
        df['minute_bin'] = df['time'].dt.floor('1T')
        
        return df
    
    def _compute_t31_analysis(self) -> Dict:
        """T31 (ì¥ë¹„) ë¶„ì„ - Operation Heatmap ì‚¬ì „ ê³„ì‚° í¬í•¨"""
        df = self._add_time_features(self.t31_df)
        
        results = {}
        
        # =======================================================================
        # 2ë¶„ ë‹¨ìœ„ unique MAC ì¹´ìš´íŒ… (T31ë„ ë™ì¼í•˜ê²Œ ì ìš©)
        # =======================================================================
        print("    ğŸ“Š 2ë¶„ ë‹¨ìœ„ unique MAC ì¹´ìš´íŒ… (T31)...")
        
        df['two_min_bin'] = df['time'].dt.floor('2T')
        
        two_min_unique = df.groupby(['date', 'two_min_bin'])['mac'].nunique().reset_index()
        two_min_unique.columns = ['date', 'two_min_bin', 'unique_mac_count']
        two_min_unique['hour'] = pd.to_datetime(two_min_unique['two_min_bin']).dt.hour
        results['two_min_unique_mac'] = two_min_unique
        
        # =======================================================================
        # 1. ì‹œê°„ëŒ€ë³„ ì¥ë¹„ ê°€ë™ í˜„í™©
        # =======================================================================
        hourly_activity = df.groupby(['date', 'hour']).agg({
            'mac': 'nunique',
            'sward_id': 'nunique',
            'rssi': 'mean'
        }).reset_index()
        hourly_activity.columns = ['date', 'hour', 'active_devices', 'active_swards', 'avg_rssi']
        results['hourly_activity'] = hourly_activity
        
        # =======================================================================
        # 2. ì¥ë¹„ë³„ ê°€ë™ ì‹œê°„
        # =======================================================================
        device_stats = df.groupby('mac').agg({
            'time': ['min', 'max', 'count'],
            'sward_id': 'nunique',
            'rssi': 'mean'
        }).reset_index()
        device_stats.columns = ['mac', 'first_seen', 'last_seen', 'record_count', 'sward_count', 'avg_rssi']
        device_stats['duration_minutes'] = (
            pd.to_datetime(device_stats['last_seen']) - pd.to_datetime(device_stats['first_seen'])
        ).dt.total_seconds() / 60
        results['device_stats'] = device_stats
        
        # =======================================================================
        # 3. S-Wardë³„ ì¥ë¹„ í˜„í™© + Operation Heatmap ë°ì´í„°
        # =======================================================================
        if self.sward_config is not None:
            sward_activity = df.groupby('sward_id').agg({
                'mac': 'nunique',
                'time': 'count',
                'rssi': 'mean'
            }).reset_index()
            sward_activity.columns = ['sward_id', 'device_count', 'record_count', 'avg_rssi']
            
            # S-Ward ì •ë³´ ì¡°ì¸
            sward_activity = sward_activity.merge(
                self.sward_config[['sward_id', 'building', 'level', 'x', 'y', 'space_type']],
                on='sward_id',
                how='left'
            )
            results['sward_activity'] = sward_activity
            
            # =======================================================================
            # Operation Heatmap: 10ë¶„ ë‹¨ìœ„ ì¥ë¹„ ê°€ë™ë¥  (í•µì‹¬)
            # =======================================================================
            print("    ğŸ“Š Operation Heatmap ìƒì„± ì¤‘...")
            
            df['time_slot_10min'] = df['time'].dt.floor('10T')
            
            # S-Ward ì •ë³´ ì¡°ì¸
            df_with_loc = df.merge(
                self.sward_config[['sward_id', 'building', 'level', 'space_type', 'x', 'y']],
                on='sward_id',
                how='left'
            )
            
            # 10ë¶„ ë‹¨ìœ„, S-Wardë³„ ì¥ë¹„ ê°€ë™ í˜„í™©
            operation_heatmap = df_with_loc.groupby([
                'date', 'time_slot_10min', 'building', 'level', 'sward_id', 'x', 'y', 'space_type'
            ]).agg({
                'mac': ['nunique', 'count'],  # ê³ ìœ  ì¥ë¹„ ìˆ˜, ì´ ë ˆì½”ë“œ ìˆ˜
                'rssi': 'mean'
            }).reset_index()
            operation_heatmap.columns = ['date', 'time_slot', 'building', 'level', 'sward_id', 
                                          'x', 'y', 'space_type', 'active_devices', 'record_count', 'avg_rssi']
            
            # ì‹œê°„ bin ì¸ë±ìŠ¤ ì¶”ê°€ (0-143, 10ë¶„ ë‹¨ìœ„)
            operation_heatmap['bin_index'] = (
                pd.to_datetime(operation_heatmap['time_slot']).dt.hour * 6 + 
                pd.to_datetime(operation_heatmap['time_slot']).dt.minute // 10
            )
            
            results['operation_heatmap'] = operation_heatmap
            print(f"    âœ… Operation Heatmap: {len(operation_heatmap):,} records")
        
        print(f"  âœ… T31 ë¶„ì„ ì™„ë£Œ: {len(device_stats)} ì¥ë¹„, {len(hourly_activity)} ì‹œê°„ëŒ€ ë ˆì½”ë“œ")
        
        return results
    
    def _compute_t41_analysis(self) -> Dict:
        """T41 (ì‘ì—…ì í—¬ë©§) ë¶„ì„ - 2ë¶„ ë‹¨ìœ„ unique MAC í¬í•¨"""
        import sys
        
        print(f"    ğŸ“Š T41 ë°ì´í„°: {len(self.t41_df):,} records", flush=True)
        print(f"    ğŸ”„ ì‹œê°„ íŠ¹ì„± ì¶”ê°€ ì¤‘...", flush=True)
        df = self._add_time_features(self.t41_df)
        print(f"    âœ… ì‹œê°„ íŠ¹ì„± ì¶”ê°€ ì™„ë£Œ", flush=True)
        
        results = {}
        
        # =======================================================================
        # 2ë¶„ ë‹¨ìœ„ unique MAC ì¹´ìš´íŒ… (T41ë„ ë™ì¼í•˜ê²Œ ì ìš©)
        # =======================================================================
        print("    ğŸ“Š 2ë¶„ ë‹¨ìœ„ unique MAC ì¹´ìš´íŒ… (T41)...", flush=True)
        sys.stdout.flush()
        
        df['two_min_bin'] = df['time'].dt.floor('2T')
        
        two_min_unique = df.groupby(['date', 'two_min_bin'])['mac'].nunique().reset_index()
        two_min_unique.columns = ['date', 'two_min_bin', 'unique_mac_count']
        two_min_unique['hour'] = pd.to_datetime(two_min_unique['two_min_bin']).dt.hour
        results['two_min_unique_mac'] = two_min_unique
        
        # ì‹œê°„ëŒ€ë³„ í‰ê·  (2ë¶„ binsì˜ í‰ê· )
        hourly_avg_from_2min = two_min_unique.groupby(['date', 'hour']).agg({
            'unique_mac_count': ['mean', 'max', 'min', 'count']
        }).reset_index()
        hourly_avg_from_2min.columns = ['date', 'hour', 'avg_workers', 'max_workers', 
                                         'min_workers', 'two_min_bin_count']
        results['hourly_avg_from_2min'] = hourly_avg_from_2min
        
        print(f"    âœ… 2ë¶„ ë‹¨ìœ„ ì§‘ê³„: {len(two_min_unique)} bins")
        
        # =======================================================================
        # 1. ì‘ì—…ìë³„ ì²´ë¥˜ì‹œê°„ ê³„ì‚°
        # =======================================================================
        worker_dwell = df.groupby('mac').agg({
            'minute_bin': 'nunique',  # ì²´ë¥˜ ì‹œê°„ (ë¶„)
            'time': ['min', 'max', 'count'],
            'sward_id': 'nunique',
            'rssi': 'mean'
        }).reset_index()
        worker_dwell.columns = ['mac', 'dwell_time_minutes', 'first_seen', 'last_seen', 
                                 'record_count', 'sward_count', 'avg_rssi']
        results['worker_dwell'] = worker_dwell
        
        # =======================================================================
        # 2. ì‹œê°„ëŒ€ë³„ ì‘ì—…ì ìˆ˜ (Occupancy) - 10ë¶„ ë‹¨ìœ„
        # =======================================================================
        time_slot_minutes = self.config.occupancy_time_unit_minutes
        df['time_slot'] = df['time'].dt.floor(f'{time_slot_minutes}T')
        
        occupancy = df.groupby(['date', 'time_slot']).agg({
            'mac': 'nunique'
        }).reset_index()
        occupancy.columns = ['date', 'time_slot', 'worker_count']
        occupancy['hour'] = pd.to_datetime(occupancy['time_slot']).dt.hour
        occupancy['minute'] = pd.to_datetime(occupancy['time_slot']).dt.minute
        results['occupancy'] = occupancy
        
        # =======================================================================
        # 3. Building/Levelë³„ ì‘ì—…ì í˜„í™©
        # =======================================================================
        if self.sward_config is not None:
            # S-Ward ì •ë³´ ì¡°ì¸
            df_with_location = df.merge(
                self.sward_config[['sward_id', 'building', 'level', 'space_type']],
                on='sward_id',
                how='left'
            )
            
            # Buildingë³„ ì‹œê°„ëŒ€ ì‘ì—…ì ìˆ˜
            building_occupancy = df_with_location.groupby(['date', 'time_slot', 'building', 'level']).agg({
                'mac': 'nunique'
            }).reset_index()
            building_occupancy.columns = ['date', 'time_slot', 'building', 'level', 'worker_count']
            results['building_occupancy'] = building_occupancy
            
            # Space Typeë³„ ì‘ì—…ì í˜„í™©
            space_type_stats = df_with_location.groupby(['space_type']).agg({
                'mac': 'nunique',
                'time': 'count'
            }).reset_index()
            space_type_stats.columns = ['space_type', 'unique_workers', 'total_records']
            results['space_type_stats'] = space_type_stats
        
        # 4. Journey ë¶„ì„ (ì‘ì—…ì ì´ë™ ê²½ë¡œ)
        journey_data = self._compute_worker_journey(df)
        results['journey_data'] = journey_data
        
        # 5. í•„í„°ë§ëœ ë°ì´í„° (ì²´ë¥˜ì‹œê°„ >= 30ë¶„)
        filtered_macs = worker_dwell[worker_dwell['dwell_time_minutes'] >= self.config.min_dwell_time_minutes]['mac'].tolist()
        results['filtered_worker_count'] = len(filtered_macs)
        results['total_worker_count'] = len(worker_dwell)
        
        # 6. ğŸ†• Activity Analysis ìƒì„± (Journey Heatmapìš©)
        # 1ë¶„ ë‹¨ìœ„ í™œë™ ìƒíƒœ ë¶„ì„ - Journey Mapì—ì„œ í•„ìš”
        print("    ğŸ“Š Activity Analysis ìƒì„± ì¤‘...")
        activity_analysis = self._compute_activity_analysis(df)
        results['activity_analysis'] = activity_analysis
        print(f"    âœ… Activity Analysis: {len(activity_analysis):,} records")
        
        # 7. ğŸ†• Journey Heatmap precomputation (10ë¶„ ë‹¨ìœ„ ë²¡í„°í™”)
        print("    ğŸ“Š Journey Heatmap precomputation ì‹œì‘...")
        journey_heatmap = self._compute_journey_heatmap(df)
        results['journey_heatmap'] = journey_heatmap
        print(f"    âœ… Journey Heatmap: {len(journey_heatmap):,} records")
        
        print(f"  âœ… T41 ë¶„ì„ ì™„ë£Œ: {len(worker_dwell)} ì‘ì—…ì, í•„í„°ë§ í›„ {len(filtered_macs)}ëª…")
        
        return results
    
    def _compute_activity_analysis(self, df: pd.DataFrame) -> pd.DataFrame:
        """ì‘ì—…ì í™œë™ ìƒíƒœ ë¶„ì„ (1ë¶„ ë‹¨ìœ„) - Journey Heatmapìš©
        
        ë²¡í„°í™”ëœ ìµœì í™” ë²„ì „: for ë£¨í”„ ëŒ€ì‹  groupby + agg ì‚¬ìš©
        """
        if self.sward_config is None:
            return pd.DataFrame()
        
        import sys
        print(f"      ğŸ”„ S-Ward ì •ë³´ ì¡°ì¸ ì¤‘...", flush=True)
        sys.stdout.flush()
        # S-Ward ì •ë³´ ì¡°ì¸
        df_with_loc = df.merge(
            self.sward_config[['sward_id', 'building', 'level', 'space_type']],
            on='sward_id',
            how='left'
        )
        
        print("      ğŸ”„ ë²¡í„°í™”ëœ ì§‘ê³„ ì¤‘...", flush=True)
        sys.stdout.flush()
        
        # ë²¡í„°í™”ëœ ì§‘ê³„: mac + minute_bin ê·¸ë£¹ìœ¼ë¡œ í•œ ë²ˆì— ì²˜ë¦¬
        # ê° ê·¸ë£¹ì—ì„œ ê°€ì¥ ë§ì´ ë‚˜íƒ€ë‚œ building/level/space_typeê³¼ signal_count ê³„ì‚°
        
        # 1. ê¸°ë³¸ ì§‘ê³„: signal_count
        basic_agg = df_with_loc.groupby(['mac', 'minute_bin']).agg({
            'sward_id': 'count',  # signal_count
        }).reset_index()
        basic_agg.columns = ['mac', 'minute_bin', 'signal_count']
        
        print("      ğŸ”„ ìµœë¹ˆê°’ ê³„ì‚° ì¤‘ (ìµœì í™” ë²„ì „)...", flush=True)
        sys.stdout.flush()
        
        # 2. ìµœë¹ˆê°’ ê³„ì‚°: value_counts().idxmax() ëŒ€ì‹  ë” ë¹ ë¥¸ ë°©ë²• ì‚¬ìš©
        # ê° ì»¬ëŸ¼ë³„ë¡œ ê°€ì¥ ë¹ˆë„ê°€ ë†’ì€ ê°’ì„ ì°¾ìŒ
        
        # building ìµœë¹ˆê°’: ê·¸ë£¹ë³„ ì²« ë²ˆì§¸ ê°’ ì‚¬ìš© (modeë³´ë‹¤ í›¨ì”¬ ë¹ ë¦„)
        # ì‹¤ì œ modeë¥¼ êµ¬í•˜ë ¤ë©´ ë„ˆë¬´ ëŠë¦¬ë¯€ë¡œ, ê·¸ë£¹ ë‚´ ê°€ì¥ ë¨¼ì € ë‚˜íƒ€ë‚œ ê°’ ì‚¬ìš©
        building_first = df_with_loc.groupby(['mac', 'minute_bin'])['building'].first().reset_index()
        building_first.columns = ['mac', 'minute_bin', 'building']
        
        print("      ğŸ”„ level ê°’ ì¶”ì¶œ ì¤‘...", flush=True)
        sys.stdout.flush()
        # level ì²« ë²ˆì§¸ ê°’
        level_first = df_with_loc.groupby(['mac', 'minute_bin'])['level'].first().reset_index()
        level_first.columns = ['mac', 'minute_bin', 'level']
        
        print("      ğŸ”„ space_type ê°’ ì¶”ì¶œ ì¤‘...", flush=True)
        sys.stdout.flush()
        # space_type ì²« ë²ˆì§¸ ê°’
        space_type_first = df_with_loc.groupby(['mac', 'minute_bin'])['space_type'].first().reset_index()
        space_type_first.columns = ['mac', 'minute_bin', 'space_type']
        
        print("      ğŸ”„ ê²°ê³¼ ë³‘í•© ì¤‘...", flush=True)
        sys.stdout.flush()
        
        # 3. ê²°ê³¼ ë³‘í•©
        result = basic_agg.merge(building_first, on=['mac', 'minute_bin'], how='left')
        result = result.merge(level_first, on=['mac', 'minute_bin'], how='left')
        result = result.merge(space_type_first, on=['mac', 'minute_bin'], how='left')
        
        # 4. activity_status ê³„ì‚° (ë²¡í„°í™”)
        result['activity_status'] = 'Absent'
        result.loc[result['signal_count'] >= 1, 'activity_status'] = 'Present'
        result.loc[result['signal_count'] >= 3, 'activity_status'] = 'Active'
        
        print(f"      âœ… Activity Analysis ì™„ë£Œ: {len(result):,} records")
        
        return result
    
    def _compute_worker_journey(self, df: pd.DataFrame) -> pd.DataFrame:
        """ì‘ì—…ì ì´ë™ ê²½ë¡œ ë¶„ì„"""
        if self.sward_config is None:
            return pd.DataFrame()
        
        # S-Ward ìœ„ì¹˜ ì •ë³´ ì¡°ì¸
        df_journey = df.merge(
            self.sward_config[['sward_id', 'building', 'level', 'x', 'y']],
            on='sward_id',
            how='left'
        )
        
        # ì‘ì—…ìë³„ ì´ë™ ê²½ë¡œ ì¶”ì¶œ
        journeys = []
        for mac, group in df_journey.groupby('mac'):
            group = group.sort_values('time')
            
            # ì—°ì†ëœ ë™ì¼ S-Ward ì œê±° (ì‹¤ì œ ì´ë™ë§Œ ì¶”ì¶œ)
            group['sward_changed'] = group['sward_id'] != group['sward_id'].shift()
            transitions = group[group['sward_changed']].copy()
            
            if len(transitions) > 1:
                journeys.append({
                    'mac': mac,
                    'transition_count': len(transitions) - 1,
                    'unique_swards': group['sward_id'].nunique(),
                    'first_sward': transitions.iloc[0]['sward_id'],
                    'last_sward': transitions.iloc[-1]['sward_id'],
                    'start_time': transitions.iloc[0]['time'],
                    'end_time': transitions.iloc[-1]['time']
                })
        
        return pd.DataFrame(journeys)
    
    def _compute_journey_heatmap(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Journey Heatmap ì „ìš© ë²¡í„°í™” precomputation (2ë¶„â†’10ë¶„ ë¡¤ì—… ë°©ì‹)
        
        íš¨ìœ¨ì ì¸ ì²˜ë¦¬ ìˆœì„œ:
        1. 2ë¶„ ë‹¨ìœ„ë¡œ ê° (mac, 2min_bin)ì˜ building, level ì§‘ê³„
        2. 2ë¶„ binì„ 10ë¶„ binìœ¼ë¡œ ë¡¤ì—… (5ê°œ 2ë¶„ bin â†’ 1ê°œ 10ë¶„ bin)
        3. ê° 10ë¶„ binì—ì„œ ê°€ì¥ ë¹ˆë²ˆí•œ building-level ê²°ì •
        4. 144ê°œ time bin í–‰ë ¬ ìƒì„± (workers Ã— 144)
        
        - Xì¶•: 10ë¶„ ë‹¨ìœ„ bins (144ê°œ, 00:00~23:50)
        - Yì¶•: ê°œë³„ ì‘ì—…ì (MAC)
        - ìƒ‰ìƒ: Building-Level ìœ„ì¹˜ (JOURNEY_COLORS ê¸°ë°˜)
        """
        if self.sward_config is None or df.empty:
            return pd.DataFrame()
        
        print("    ğŸ—ºï¸ Journey Heatmap precomputation ì‹œì‘ (2ë¶„â†’10ë¶„ ë¡¤ì—…)...")
        sys.stdout.flush()
        
        # =====================================================================
        # Step 1: S-Ward ìœ„ì¹˜ ì •ë³´ ì¡°ì¸
        # =====================================================================
        df_with_loc = df.merge(
            self.sward_config[['sward_id', 'building', 'level']],
            on='sward_id',
            how='left'
        )
        
        # Building-Level ì¡°í•© ìƒì„±
        df_with_loc['building_level'] = (
            df_with_loc['building'].fillna('Unknown') + '-' + 
            df_with_loc['level'].fillna('Unknown')
        )
        
        # =====================================================================
        # Step 2: 2ë¶„ ë‹¨ìœ„ë¡œ ì§‘ê³„ (ê¸°ë³¸ ë‹¨ìœ„)
        # =====================================================================
        print("      ğŸ”„ Step 1/3: 2ë¶„ ë‹¨ìœ„ ì§‘ê³„ ì¤‘...", flush=True)
        sys.stdout.flush()
        
        df_with_loc['two_min_bin'] = df_with_loc['time'].dt.floor('2min')
        
        # ê° (mac, 2min_bin)ì—ì„œ ì²« ë²ˆì§¸ building_levelê³¼ ì‹ í˜¸ ìˆ˜
        two_min_agg = df_with_loc.groupby(['mac', 'two_min_bin']).agg({
            'building_level': 'first',
            'building': 'first',
            'level': 'first',
            'time': 'count'  # í•´ë‹¹ 2ë¶„ ë™ì•ˆì˜ ì‹ í˜¸ ìˆ˜
        }).reset_index()
        two_min_agg.columns = ['mac', 'two_min_bin', 'building_level', 'building', 'level', 'signal_count_2min']
        
        print(f"      âœ… 2ë¶„ ì§‘ê³„ ì™„ë£Œ: {len(two_min_agg):,} records")
        
        # =====================================================================
        # Step 3: 2ë¶„ â†’ 10ë¶„ ë¡¤ì—…
        # =====================================================================
        print("      ğŸ”„ Step 2/3: 10ë¶„ ë‹¨ìœ„ë¡œ ë¡¤ì—… ì¤‘...", flush=True)
        sys.stdout.flush()
        
        # 10ë¶„ bin ì¸ë±ìŠ¤ ê³„ì‚° (0~143)
        two_min_agg['ten_min_bin'] = two_min_agg['two_min_bin'].dt.floor('10min')
        two_min_agg['bin_index'] = (
            two_min_agg['two_min_bin'].dt.hour * 6 + 
            two_min_agg['two_min_bin'].dt.minute // 10
        )
        
        # ê° 10ë¶„ binì—ì„œ ê°€ì¥ ë§ì´ ë‚˜íƒ€ë‚œ building_level ì°¾ê¸°
        # ë°©ë²•: ê° (mac, bin_index, building_level)ë³„ 2ë¶„ bin ìˆ˜ë¥¼ ì„¸ê³ , ìµœëŒ€ê°’ ì„ íƒ
        ten_min_counts = two_min_agg.groupby(['mac', 'bin_index', 'building_level']).agg({
            'signal_count_2min': 'sum',  # í•´ë‹¹ building_levelì—ì„œì˜ ì´ ì‹ í˜¸ ìˆ˜
            'two_min_bin': 'count'  # í•´ë‹¹ building_levelì´ ë‚˜íƒ€ë‚œ 2ë¶„ bin ìˆ˜
        }).reset_index()
        ten_min_counts.columns = ['mac', 'bin_index', 'building_level', 'signal_count', 'two_min_bin_count']
        
        # ê° (mac, bin_index)ì—ì„œ two_min_bin_countê°€ ê°€ì¥ ë†’ì€ building_level ì„ íƒ
        idx = ten_min_counts.groupby(['mac', 'bin_index'])['two_min_bin_count'].idxmax()
        journey_data = ten_min_counts.loc[idx].copy()
        
        # building, level ë¶„ë¦¬
        journey_data[['building', 'level']] = journey_data['building_level'].str.split('-', n=1, expand=True)
        
        print(f"      âœ… 10ë¶„ ë¡¤ì—… ì™„ë£Œ: {len(journey_data):,} records")
        
        # =====================================================================
        # Step 4: ìƒ‰ìƒ ì½”ë“œ ë§¤í•‘ (ì™„ì „ ë²¡í„°í™”)
        # =====================================================================
        print("      ğŸ”„ Step 3/3: ìƒ‰ìƒ ì½”ë“œ ë§¤í•‘ ì¤‘...", flush=True)
        sys.stdout.flush()
        
        # ìƒ‰ìƒ ì½”ë“œ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬
        # 0: no_signal, 1: present_inactive, 2+: Building-Levelë³„ active ìƒ‰ìƒ
        color_mapping = {
            'WWT-1F': 2,
            'WWT-B1F': 3,
            'WWT-2F': 2,
            'FAB-1F': 4,
            'FAB-B1F': 4,
            'FAB-2F': 4,
            'CUB-1F': 5,
            'CUB-B1F': 6,
            'CUB-2F': 5,
            'Cluster-1F': 7,
            'Cluster-B1F': 7,
            'Cluster-2F': 7,
            'Unknown-Unknown': 0
        }
        
        # ë²¡í„°í™”ëœ ìƒ‰ìƒ ì½”ë“œ í• ë‹¹
        # 1. ë¨¼ì € building_levelë¡œ ê¸°ë³¸ ìƒ‰ìƒ ë§¤í•‘
        # ì•Œ ìˆ˜ ì—†ëŠ” building_levelì€ 7(Cluster)ë¡œ ë§¤í•‘ (ê¸°ì¡´ 9 ëŒ€ì‹ )
        journey_data['base_color'] = journey_data['building_level'].map(color_mapping).fillna(7).astype(int)
        
        # color_codeê°€ 7ì„ ì´ˆê³¼í•˜ì§€ ì•Šë„ë¡ í´ë¨í•‘
        journey_data['base_color'] = journey_data['base_color'].clip(upper=7)
        
        # 2. í™œì„±/ë¹„í™œì„± íŒë‹¨ (T41 í—¬ë©§ íŠ¹ì„± ê¸°ë°˜)
        # - í™œì„±: ì§„ë™ ê°ì§€ â†’ 1ë¶„ì— 2íšŒ ì´ìƒ ì‹ í˜¸ (10ì´ˆ ê°„ê²©)
        # - ë¹„í™œì„±: ì§„ë™ ì—†ìŒ â†’ 1ë¶„ì— 2íšŒ ë¯¸ë§Œ ì‹ í˜¸
        # - 10ë¶„ ê¸°ì¤€: 20íšŒ ì´ìƒì´ë©´ í™œì„± (1ë¶„ì— 2íšŒ Ã— 10ë¶„)
        ACTIVE_THRESHOLD = 20  # 10ë¶„ ë™ì•ˆ 20íšŒ ì´ìƒ ì‹ í˜¸ = í™œì„±
        
        journey_data['color_code'] = np.where(
            journey_data['signal_count'] < ACTIVE_THRESHOLD,
            1,  # present_inactive (ë¹„í™œì„±: ì‹ í˜¸ëŠ” ìˆì§€ë§Œ ì§„ë™ ì—†ìŒ)
            journey_data['base_color']
        )
        
        # ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì œê±°
        journey_data = journey_data.drop(columns=['two_min_bin_count', 'base_color'])
        
        # í†µê³„
        all_macs = journey_data['mac'].nunique()
        total_bins = len(journey_data)
        
        print(f"      âœ… Journey Heatmap ì™„ë£Œ: {total_bins:,} records, {all_macs:,} workers")
        print(f"         í‰ê·  bin/worker: {total_bins/all_macs:.1f} (ìµœëŒ€ 144)")
        sys.stdout.flush()
        
        return journey_data
    
    def _compute_flow_analysis(self) -> Dict:
        """Flow (ìŠ¤ë§ˆíŠ¸í°) ë¶„ì„ - 2ë¶„ ë‹¨ìœ„ unique MAC ì¹´ìš´íŒ…"""
        df = self._add_time_features(self.flow_df)
        
        results = {}
        
        # =======================================================================
        # 2ë¶„ ë‹¨ìœ„ unique MAC ì¹´ìš´íŒ… (í•µì‹¬ ë¡œì§)
        # MAC ì£¼ì†Œê°€ ìì£¼ ë³€ê²½ë˜ë¯€ë¡œ 2ë¶„ ë‹¨ìœ„ë¡œ ê³ ìœ  MAC ìˆ˜ë¥¼ ì„¸ì–´ í‰ê· 
        # =======================================================================
        print("    ğŸ“Š 2ë¶„ ë‹¨ìœ„ unique MAC ì¹´ìš´íŒ… ì¤‘...")
        
        # 2ë¶„ ë‹¨ìœ„ bin ìƒì„±
        df['two_min_bin'] = df['time'].dt.floor('2T')
        
        # 2ë¶„ ë‹¨ìœ„ unique MAC ì¹´ìš´íŠ¸
        two_min_unique = df.groupby(['date', 'two_min_bin'])['mac'].nunique().reset_index()
        two_min_unique.columns = ['date', 'two_min_bin', 'unique_mac_count']
        two_min_unique['hour'] = pd.to_datetime(two_min_unique['two_min_bin']).dt.hour
        results['two_min_unique_mac'] = two_min_unique
        
        # ì‹œê°„ëŒ€ë³„ í‰ê·  (2ë¶„ binsì˜ í‰ê· )
        hourly_avg_from_2min = two_min_unique.groupby(['date', 'hour']).agg({
            'unique_mac_count': ['mean', 'max', 'min', 'sum', 'count']
        }).reset_index()
        hourly_avg_from_2min.columns = ['date', 'hour', 'avg_unique_mac', 'max_unique_mac', 
                                         'min_unique_mac', 'sum_unique_mac', 'two_min_bin_count']
        results['hourly_avg_from_2min'] = hourly_avg_from_2min
        
        print(f"    âœ… 2ë¶„ ë‹¨ìœ„ ì§‘ê³„: {len(two_min_unique)} bins, ì‹œê°„ëŒ€ë³„ í‰ê· : {len(hourly_avg_from_2min)} records")
        
        # =======================================================================
        # ê¸°ì¡´ ë¶„ì„: ì‹œê°„ëŒ€ë³„ ìœ ë™ì¸êµ¬ (10ë¶„ ë‹¨ìœ„)
        # =======================================================================
        
        # 1. ì‹œê°„ëŒ€ë³„ ìœ ë™ì¸êµ¬ (10ë¶„ ë‹¨ìœ„ - ê¸°ì¡´ í˜¸í™˜)
        df['ten_min_bin'] = df['time'].dt.floor('10T')
        ten_min_unique = df.groupby(['date', 'ten_min_bin']).agg({
            'mac': 'nunique'
        }).reset_index()
        ten_min_unique.columns = ['date', 'ten_min_bin', 'unique_devices']
        results['ten_min_unique'] = ten_min_unique
        
        # 2. ì‹œê°„ëŒ€ë³„ ìœ ë™ì¸êµ¬ (1ì‹œê°„ ë‹¨ìœ„)
        hourly_flow = df.groupby(['date', 'hour']).agg({
            'mac': 'nunique'
        }).reset_index()
        hourly_flow.columns = ['date', 'hour', 'unique_devices']
        results['hourly_flow'] = hourly_flow
        
        # 3. S-Wardë³„ ìœ ë™ì¸êµ¬
        sward_flow = df.groupby('sward_id').agg({
            'mac': 'nunique',
            'time': 'count',
            'rssi': 'mean'
        }).reset_index()
        sward_flow.columns = ['sward_id', 'unique_devices', 'total_records', 'avg_rssi']
        
        if self.sward_config is not None:
            sward_flow = sward_flow.merge(
                self.sward_config[['sward_id', 'building', 'level', 'x', 'y', 'space_type']],
                on='sward_id',
                how='left'
            )
        results['sward_flow'] = sward_flow
        
        # 4. ë””ë°”ì´ìŠ¤ë³„ ì²´ë¥˜ ë¶„ì„
        device_stats = df.groupby('mac').agg({
            'minute_bin': 'nunique',
            'sward_id': 'nunique',
            'rssi': 'mean'
        }).reset_index()
        device_stats.columns = ['mac', 'dwell_minutes', 'sward_count', 'avg_rssi']
        results['device_stats'] = device_stats
        
        # 5. ë””ë°”ì´ìŠ¤ íƒ€ì…ë³„ ë¶„ì„ (type ì»¬ëŸ¼ì´ ìˆëŠ” ê²½ìš°)
        if 'type' in df.columns:
            type_stats = df.groupby('type')['mac'].nunique().reset_index()
            type_stats.columns = ['device_type', 'unique_devices']
            results['device_type_stats'] = type_stats
        
        print(f"  âœ… Flow ë¶„ì„ ì™„ë£Œ: {len(device_stats)} ë””ë°”ì´ìŠ¤, 2ë¶„ í‰ê·  ì‹œê°„ëŒ€ë³„: {hourly_avg_from_2min['avg_unique_mac'].sum():.0f} total avg")
        
        return results
    
    def _compute_combined_analysis(self) -> Dict:
        """í†µí•© ë¶„ì„"""
        results = {}
        
        # ë°ì´í„° ìš”ì•½
        summary = {
            't31_records': len(self.t31_df) if self.t31_df is not None else 0,
            't41_records': len(self.t41_df) if self.t41_df is not None else 0,
            'flow_records': len(self.flow_df) if self.flow_df is not None else 0,
            't31_devices': self.t31_df['mac'].nunique() if self.t31_df is not None else 0,
            't41_workers': self.t41_df['mac'].nunique() if self.t41_df is not None else 0,
            'flow_devices': self.flow_df['mac'].nunique() if self.flow_df is not None else 0,
        }
        
        # ë‚ ì§œ ë²”ìœ„
        all_times = []
        if self.t31_df is not None:
            all_times.extend(self.t31_df['time'].tolist())
        if self.t41_df is not None:
            all_times.extend(self.t41_df['time'].tolist())
        if self.flow_df is not None:
            all_times.extend(self.flow_df['time'].tolist())
        
        if all_times:
            summary['date_range_start'] = min(all_times).isoformat()
            summary['date_range_end'] = max(all_times).isoformat()
            summary['dates'] = sorted(list(set([t.strftime('%Y-%m-%d') for t in all_times])))
        
        results['summary'] = summary
        
        print(f"  âœ… í†µí•© ë¶„ì„ ì™„ë£Œ")
        
        return results
    
    def _compute_heatmap_data(self) -> Dict:
        """íˆíŠ¸ë§µ ë°ì´í„° ìƒì„±"""
        results = {}
        
        if self.sward_config is None:
            return results
        
        # T41 íˆíŠ¸ë§µ (ì‘ì—…ì ë°€ë„)
        if self.t41_df is not None:
            df = self._add_time_features(self.t41_df)
            df['time_slot'] = df['time'].dt.floor(f"{self.config.heatmap_time_slot_minutes}T")
            
            # S-Wardë³„ ì‹œê°„ëŒ€ë³„ ì‘ì—…ì ìˆ˜
            heatmap_data = df.merge(
                self.sward_config[['sward_id', 'building', 'level', 'x', 'y']],
                on='sward_id',
                how='left'
            )
            
            # ê° building/levelë³„ë¡œ ì €ì¥
            for (building, level), group in heatmap_data.groupby(['building', 'level']):
                key = f"heatmap_t41_{building}_{level}"
                
                slot_data = group.groupby(['time_slot', 'sward_id', 'x', 'y']).agg({
                    'mac': 'nunique'
                }).reset_index()
                slot_data.columns = ['time_slot', 'sward_id', 'x', 'y', 'worker_count']
                
                results[key] = slot_data
        
        print(f"  âœ… íˆíŠ¸ë§µ ë°ì´í„° ìƒì„± ì™„ë£Œ: {len(results)} ê°œ")
        
        return results
    
    def _generate_location_heatmaps(self):
        """T41 ì‘ì—…ì ìœ„ì¹˜ íˆíŠ¸ë§µ ì´ë¯¸ì§€ ìƒì„± (ë™ì˜ìƒ ëŒ€ì²´)"""
        try:
            from scipy.ndimage import gaussian_filter
        except ImportError:
            print("  âš ï¸ scipy ë¯¸ì„¤ì¹˜ - íˆíŠ¸ë§µ ìƒì„± ê±´ë„ˆëœ€")
            print("    ì„¤ì¹˜: pip install scipy")
            return
        
        if self.t41_df is None or len(self.t41_df) == 0:
            print("  âš ï¸ T41 ë°ì´í„° ì—†ìŒ - íˆíŠ¸ë§µ ìƒì„± ê±´ë„ˆëœ€")
            return
        
        if self.sward_config is None or len(self.sward_config) == 0:
            print("  âš ï¸ S-Ward ì„¤ì • ì—†ìŒ - íˆíŠ¸ë§µ ìƒì„± ê±´ë„ˆëœ€")
            return
        
        # ìŠ¤í¬ë¦½íŠ¸ ê²½ë¡œ ê¸°ì¤€ìœ¼ë¡œ ë§µ ì´ë¯¸ì§€ í´ë” ì°¾ê¸°
        script_dir = Path(__file__).parent.resolve()
        map_folder = script_dir / "Datafile" / "Map_Image"
        
        if not map_folder.exists():
            print(f"  âš ï¸ ë§µ ì´ë¯¸ì§€ í´ë” ì—†ìŒ: {map_folder}")
            return
        
        # Building-Level ì¡°í•© ì¶”ì¶œ
        building_levels = self.sward_config.groupby(['building', 'level']).size().reset_index()[['building', 'level']]
        
        # ìºì‹œ í´ë” ìƒì„±
        self.cache_folder.mkdir(parents=True, exist_ok=True)
        
        heatmap_count = 0
        
        for _, row in building_levels.iterrows():
            building = row['building']
            level = row['level']
            
            # ë§µ ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°
            map_patterns = [
                f"Map_{building}_{level}.png",
                f"map_{building}_{level}.png",
                f"Map_{building}.png",
            ]
            
            map_path = None
            for pattern in map_patterns:
                candidate = map_folder / pattern
                if candidate.exists():
                    map_path = candidate
                    break
            
            if map_path is None:
                print(f"    â­ï¸ {building}-{level}: ë§µ ì´ë¯¸ì§€ ì—†ìŒ")
                continue
            
            # íˆíŠ¸ë§µ ì´ë¯¸ì§€ ìƒì„±
            heatmap_path = self._create_location_heatmap(building, level, map_path)
            if heatmap_path:
                heatmap_count += 1
                print(f"    âœ… {building}-{level}: {heatmap_path.name}")
        
        print(f"  âœ… íˆíŠ¸ë§µ ìƒì„± ì™„ë£Œ: {heatmap_count} ê°œ")
    
    def _create_location_heatmap(self, building: str, level: str, map_path: Path) -> Optional[Path]:
        """ë‹¨ì¼ Building-Levelì— ëŒ€í•œ ìœ„ì¹˜ íˆíŠ¸ë§µ ì´ë¯¸ì§€ ìƒì„±"""
        from PIL import Image
        from scipy.ndimage import gaussian_filter
        import matplotlib.pyplot as plt
        from matplotlib.colors import LinearSegmentedColormap
        
        try:
            # ë§µ ì´ë¯¸ì§€ ë¡œë“œ
            map_img = Image.open(map_path).convert('RGB')
            img_width, img_height = map_img.size
            
            # í•´ë‹¹ Building-Levelì˜ S-Ward í•„í„°ë§
            sward_in_level = self.sward_config[
                (self.sward_config['building'] == building) & 
                (self.sward_config['level'] == level)
            ]
            
            if sward_in_level.empty or 'x' not in sward_in_level.columns:
                return None
            
            # T41 ë°ì´í„°ì™€ S-Ward ì¡°ì¸
            t41_with_loc = self.t41_df.merge(
                self.sward_config[['sward_id', 'building', 'level', 'x', 'y']],
                on='sward_id',
                how='inner'
            )
            
            # í•´ë‹¹ Building-Level í•„í„°ë§
            t41_filtered = t41_with_loc[
                (t41_with_loc['building'] == building) & 
                (t41_with_loc['level'] == level)
            ]
            
            if t41_filtered.empty:
                return None
            
            # íˆíŠ¸ë§µ ë°°ì—´ ìƒì„± (ê° ì¢Œí‘œì— ë°©ë¬¸ íšŸìˆ˜ ëˆ„ì )
            heatmap = np.zeros((img_height, img_width), dtype=np.float32)
            
            # ê° S-Ward ì¢Œí‘œë³„ ë°©ë¬¸ íšŸìˆ˜ ì§‘ê³„
            visit_counts = t41_filtered.groupby(['x', 'y']).size().reset_index(name='count')
            
            for _, row in visit_counts.iterrows():
                x = int(row['x'])
                y = int(row['y'])
                count = row['count']
                
                # ì´ë¯¸ì§€ ë²”ìœ„ ë‚´ ì²´í¬
                if 0 <= x < img_width and 0 <= y < img_height:
                    heatmap[y, x] += count
            
            # Gaussian blur ì ìš© (sigma=30ìœ¼ë¡œ ë¶€ë“œëŸ¬ìš´ íˆíŠ¸ë§µ)
            heatmap = gaussian_filter(heatmap, sigma=30)
            
            # ì •ê·œí™”
            if heatmap.max() > 0:
                heatmap = heatmap / heatmap.max()
            
            # ì»¬ëŸ¬ë§µ ìƒì„± (íŒŒë‘ â†’ ì²­ë¡ â†’ ë…¸ë‘ â†’ ì£¼í™© â†’ ë¹¨ê°•)
            cmap = LinearSegmentedColormap.from_list(
                'traffic_heatmap',
                [(0, 'blue'), (0.25, 'cyan'), (0.5, 'yellow'), (0.75, 'orange'), (1, 'red')]
            )
            
            # matplotlibìœ¼ë¡œ ì´ë¯¸ì§€ ìƒì„±
            fig, ax = plt.subplots(figsize=(img_width/100, img_height/100), dpi=100)
            
            # ë°°ê²½ ì´ë¯¸ì§€
            ax.imshow(map_img, extent=[0, img_width, img_height, 0])
            
            # íˆíŠ¸ë§µ ì˜¤ë²„ë ˆì´ (alpha=0.6)
            ax.imshow(heatmap, cmap=cmap, alpha=0.6, 
                      extent=[0, img_width, img_height, 0],
                      vmin=0, vmax=1)
            
            # S-Ward ìœ„ì¹˜ í‘œì‹œ (ì‘ì€ ë§ˆì»¤)
            for _, sward in sward_in_level.iterrows():
                ax.plot(sward['x'], sward['y'], 'ko', markersize=4, alpha=0.5)
            
            # ì¶• ì„¤ì •
            ax.set_xlim(0, img_width)
            ax.set_ylim(img_height, 0)  # Yì¶• ë°˜ì „
            ax.axis('off')
            
            # ì œëª©
            ax.set_title(f'{building} {level} - Worker Location Heatmap', 
                         fontsize=14, fontweight='bold', pad=10)
            
            # íŒŒì¼ ì €ì¥
            output_path = self.cache_folder / f"location_heatmap_{building}_{level}.png"
            plt.savefig(output_path, bbox_inches='tight', pad_inches=0.1, dpi=100)
            plt.close()
            
            return output_path
            
        except Exception as e:
            print(f"    âŒ {building}-{level} íˆíŠ¸ë§µ ìƒì„± ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return None

    def _save_cache(self, **result_dicts):
        """ìºì‹œ ì €ì¥"""
        self.cache_folder.mkdir(parents=True, exist_ok=True)
        
        saved_files = []
        
        # ì›ë³¸ ë°ì´í„° ì €ì¥ (Dashboard Modeì—ì„œ ê¸°ì¡´ ë¶„ì„ ê¸°ëŠ¥ ì‚¬ìš©ì„ ìœ„í•´)
        print("  ğŸ’¾ ì›ë³¸ ë°ì´í„° ì €ì¥ ì¤‘...")
        if self.t31_df is not None and len(self.t31_df) > 0:
            self.t31_df.to_parquet(self.cache_folder / "raw_t31.parquet", index=False)
            saved_files.append("raw_t31.parquet")
            print(f"    âœ… raw_t31.parquet: {len(self.t31_df):,} rows")
        
        if self.t41_df is not None and len(self.t41_df) > 0:
            self.t41_df.to_parquet(self.cache_folder / "raw_t41.parquet", index=False)
            saved_files.append("raw_t41.parquet")
            print(f"    âœ… raw_t41.parquet: {len(self.t41_df):,} rows")
        
        if self.flow_df is not None and len(self.flow_df) > 0:
            self.flow_df.to_parquet(self.cache_folder / "raw_flow.parquet", index=False)
            saved_files.append("raw_flow.parquet")
            print(f"    âœ… raw_flow.parquet: {len(self.flow_df):,} rows")
        
        if self.sward_config is not None and len(self.sward_config) > 0:
            self.sward_config.to_parquet(self.cache_folder / "raw_sward_config.parquet", index=False)
            saved_files.append("raw_sward_config.parquet")
            print(f"    âœ… raw_sward_config.parquet: {len(self.sward_config)} rows")
        
        # ë¶„ì„ ê²°ê³¼ ì €ì¥
        print("  ğŸ’¾ ë¶„ì„ ê²°ê³¼ ì €ì¥ ì¤‘...")
        for result_name, result_data in result_dicts.items():
            if isinstance(result_data, dict):
                for key, value in result_data.items():
                    if isinstance(value, pd.DataFrame) and len(value) > 0:
                        filename = f"{result_name}_{key}.parquet"
                        filepath = self.cache_folder / filename
                        value.to_parquet(filepath, index=False)
                        saved_files.append(filename)
                    elif isinstance(value, (dict, list, str, int, float)):
                        # JSONìœ¼ë¡œ ì €ì¥
                        filename = f"{result_name}_{key}.json"
                        filepath = self.cache_folder / filename
                        with open(filepath, 'w') as f:
                            json.dump(value, f, indent=2, default=str)
                        saved_files.append(filename)
        
        # ë©”íƒ€ë°ì´í„° ì €ì¥
        metadata = {
            'created_at': datetime.now().isoformat(),
            'data_folder': str(self.data_folder),
            'config': self.config.to_dict(),
            'config_hash': self.config.get_hash(),
            'saved_files': saved_files,
            't31_records': len(self.t31_df) if self.t31_df is not None else 0,
            't41_records': len(self.t41_df) if self.t41_df is not None else 0,
            'flow_records': len(self.flow_df) if self.flow_df is not None else 0,
        }
        
        with open(self.cache_folder / "metadata.json", 'w') as f:
            json.dump(metadata, f, indent=2)
        
        print(f"  âœ… {len(saved_files)} ê°œ íŒŒì¼ ì €ì¥ ì™„ë£Œ")
    
    def _compute_dashboard_data(self) -> Dict:
        """Dashboard Overview ë° íƒ­ë³„ ë°ì´í„° ì‚¬ì „ ê³„ì‚°"""
        results = {}
        
        # =====================================================================
        # T31 Overview ë°ì´í„°
        # =====================================================================
        if self.t31_df is not None and len(self.t31_df) > 0 and self.sward_config is not None:
            print("    ğŸ“Š T31 Overview ë°ì´í„° ìƒì„± ì¤‘...")
            
            t31_with_loc = self.t31_df.merge(
                self.sward_config[['sward_id', 'building', 'level', 'x', 'y']],
                on='sward_id',
                how='left'
            )
            
            # ================================================================
            # Primary Location ê¸°ì¤€ Building/Levelë³„ ì¥ë¹„ ìˆ˜ (í†µì¼ëœ ë¡œì§)
            # ê° MACì´ ê°€ì¥ ë§ì´ ê°ì§€ëœ ìœ„ì¹˜ë¥¼ Primary Locationìœ¼ë¡œ ê²°ì •
            # ================================================================
            mac_loc_counts = t31_with_loc.groupby(['mac', 'building', 'level']).size().reset_index(name='signal_count')
            idx = mac_loc_counts.groupby('mac')['signal_count'].idxmax()
            mac_primary_loc = mac_loc_counts.loc[idx][['mac', 'building', 'level', 'signal_count']]
            
            # Primary Location ê¸°ì¤€ Building/Levelë³„ ì¥ë¹„ ìˆ˜
            building_level_equipment = mac_primary_loc.groupby(['building', 'level']).size().reset_index(name='equipment_count')
            results['t31_building_level_equipment'] = building_level_equipment
            
            # ì¥ë¹„ë³„ Primary Location ì •ë³´ ì €ì¥
            results['t31_mac_primary_location'] = mac_primary_loc
            
            total_equipment = len(mac_primary_loc)
            
            # ì‹œê°„ëŒ€ë³„ ê°€ë™ë¥  (10ë¶„ ë‹¨ìœ„)
            t31_copy = t31_with_loc.copy()
            t31_copy['hour'] = t31_copy['time'].dt.hour
            t31_copy['ten_min_bin'] = t31_copy['time'].dt.floor('10min')
            t31_copy['bin_index'] = t31_copy['time'].dt.hour * 6 + t31_copy['time'].dt.minute // 10
            
            # 10ë¶„ ë‹¨ìœ„ë³„ í™œì„± ì¥ë¹„ ìˆ˜
            ten_min_active = t31_copy.groupby('bin_index')['mac'].nunique().reset_index()
            ten_min_active.columns = ['bin_index', 'active_equipment']
            ten_min_active['total_equipment'] = total_equipment
            ten_min_active['operation_rate'] = (ten_min_active['active_equipment'] / total_equipment * 100).round(1)
            ten_min_active['time_label'] = ten_min_active['bin_index'].apply(
                lambda x: f"{x // 6:02d}:{(x % 6) * 10:02d}"
            )
            results['t31_ten_min_operation_rate'] = ten_min_active
            
            # ì‹œê°„ëŒ€ë³„ í™œì„± ì¥ë¹„ ìˆ˜ (ì‹œê°„ ë‹¨ìœ„)
            hourly_active = t31_copy.groupby('hour')['mac'].nunique().reset_index()
            hourly_active.columns = ['hour', 'active_equipment']
            hourly_active['total_equipment'] = total_equipment
            hourly_active['operation_rate'] = (hourly_active['active_equipment'] / total_equipment * 100).round(1)
            results['t31_hourly_operation_rate'] = hourly_active
            
            # ê±´ë¬¼ë³„ ì‹œê°„ëŒ€ë³„ ê°€ë™ë¥ 
            building_hourly = t31_copy.groupby(['building', 'hour'])['mac'].nunique().reset_index()
            building_hourly.columns = ['building', 'hour', 'active_equipment']
            results['t31_building_hourly_active'] = building_hourly
            
            # ì¥ë¹„ë³„ ìœ„ì¹˜ (Location Analysisìš©) - Primary Location ê¸°ì¤€
            equipment_positions = mac_primary_loc.merge(
                t31_with_loc.groupby('mac').agg({
                    'x': 'mean',
                    'y': 'mean',
                    'sward_id': 'first',
                    'time': 'count'  # ì´ ì‹ í˜¸ ìˆ˜
                }).reset_index().rename(columns={'time': 'signal_count_total'}),
                on='mac',
                how='left'
            )
            
            # ì¥ë¹„ë³„ ê°€ë™ ì‹œê°„ ê³„ì‚° (10ë¶„ bin ìˆ˜ Ã— 10ë¶„)
            mac_operation_time = t31_copy.groupby('mac')['bin_index'].nunique().reset_index()
            mac_operation_time.columns = ['mac', 'active_bins']
            mac_operation_time['operation_time_min'] = mac_operation_time['active_bins'] * 10
            mac_operation_time['operation_time_hr'] = (mac_operation_time['operation_time_min'] / 60).round(1)
            
            equipment_positions = equipment_positions.merge(
                mac_operation_time[['mac', 'operation_time_min', 'operation_time_hr']],
                on='mac',
                how='left'
            )
            results['t31_equipment_positions'] = equipment_positions
            
            print(f"    âœ… T31 Overview: {len(building_level_equipment)} building-level (Primary Loc), {total_equipment} equipment")
        
        # =====================================================================
        # T41 Overview ë°ì´í„°
        # =====================================================================
        if self.t41_df is not None and len(self.t41_df) > 0 and self.sward_config is not None:
            print("    ğŸ“Š T41 Overview ë°ì´í„° ìƒì„± ì¤‘...")
            
            t41_with_loc = self.t41_df.merge(
                self.sward_config[['sward_id', 'building', 'level', 'x', 'y']],
                on='sward_id',
                how='left'
            )
            
            # ê±´ë¬¼/ì¸µë³„ ì‘ì—…ì ìˆ˜
            building_level_workers = t41_with_loc.groupby(['building', 'level'])['mac'].nunique().reset_index()
            building_level_workers.columns = ['building', 'level', 'worker_count']
            results['t41_building_level_workers'] = building_level_workers
            
            # ì‹œê°„ëŒ€ë³„ ì‘ì—…ì ìˆ˜ (10ë¶„ ë‹¨ìœ„)
            t41_copy = t41_with_loc.copy()
            t41_copy['hour'] = t41_copy['time'].dt.hour
            t41_copy['ten_min_bin'] = t41_copy['time'].dt.floor('10min')
            
            # ì „ì²´ ì‹œê°„ëŒ€ë³„ ì‘ì—…ì ìˆ˜
            hourly_workers = t41_copy.groupby('hour')['mac'].nunique().reset_index()
            hourly_workers.columns = ['hour', 'worker_count']
            results['t41_hourly_workers'] = hourly_workers
            
            # ê±´ë¬¼ë³„ ì‹œê°„ëŒ€ë³„ ì‘ì—…ì ìˆ˜
            building_hourly = t41_copy.groupby(['building', 'hour'])['mac'].nunique().reset_index()
            building_hourly.columns = ['building', 'hour', 'worker_count']
            results['t41_building_hourly_workers'] = building_hourly
            
            # ê±´ë¬¼-ì¸µë³„ ì‹œê°„ëŒ€ë³„ ì‘ì—…ì ìˆ˜
            building_level_hourly = t41_copy.groupby(['building', 'level', 'hour'])['mac'].nunique().reset_index()
            building_level_hourly.columns = ['building', 'level', 'hour', 'worker_count']
            results['t41_building_level_hourly_workers'] = building_level_hourly
            
            # ê°€ì¥ í˜¼ì¡í•œ ê±´ë¬¼/ì¸µ ì°¾ê¸°
            busiest = building_level_workers.loc[building_level_workers['worker_count'].idxmax()]
            results['t41_busiest_location'] = {
                'building': busiest['building'],
                'level': busiest['level'],
                'worker_count': int(busiest['worker_count'])
            }
            
            # 10ë¶„ ë‹¨ìœ„ ìƒì„¸ ì‘ì—…ì ìˆ˜ (ê·¸ë˜í”„ìš©)
            ten_min_workers = t41_copy.groupby('ten_min_bin')['mac'].nunique().reset_index()
            ten_min_workers.columns = ['time_bin', 'worker_count']
            results['t41_ten_min_workers'] = ten_min_workers
            
            # ê±´ë¬¼ë³„ 10ë¶„ ë‹¨ìœ„ ì‘ì—…ì ìˆ˜
            building_ten_min = t41_copy.groupby(['building', 'ten_min_bin'])['mac'].nunique().reset_index()
            building_ten_min.columns = ['building', 'time_bin', 'worker_count']
            results['t41_building_ten_min_workers'] = building_ten_min
            
            print(f"    âœ… T41 Overview: {len(building_level_workers)} building-level, {len(hourly_workers)} hours")
            
            # =================================================================
            # ğŸ†• T41 Active/Inactive Stats ì‚¬ì „ ê³„ì‚° (10ë¶„ ë‹¨ìœ„, Building/Levelë³„)
            # Overview íƒ­ê³¼ T41 íƒ­ì—ì„œ ë™ì¼í•œ ë°ì´í„° ì‚¬ìš©
            # =================================================================
            print("    ğŸ“Š T41 Active/Inactive Stats ìƒì„± ì¤‘ (Building/Levelë³„)...")
            
            t41_stats = t41_with_loc.copy()
            t41_stats['minute_bin'] = t41_stats['time'].dt.floor('1min')
            t41_stats['bin_index'] = t41_stats['time'].dt.hour * 6 + t41_stats['time'].dt.minute // 10
            
            # 1ë¶„ ë‹¨ìœ„ ì‹ í˜¸ ìˆ˜ ê³„ì‚°
            minute_signal = t41_stats.groupby(['mac', 'minute_bin', 'building', 'level']).size().reset_index(name='signals')
            minute_signal['is_active'] = minute_signal['signals'] >= 2  # 1ë¶„ì— 2íšŒ ì´ìƒ = Active
            minute_signal['bin_index'] = (
                minute_signal['minute_bin'].dt.hour * 6 + 
                minute_signal['minute_bin'].dt.minute // 10
            )
            
            # 10ë¶„ binë‹¹ í™œì„± ì—¬ë¶€ (10ë¶„ ë‚´ì— 1ë¶„ì´ë¼ë„ í™œì„±ì´ë©´ Active)
            mac_bin_activity = minute_signal.groupby(['mac', 'bin_index', 'building', 'level']).agg({
                'is_active': 'any'
            }).reset_index()
            
            def calc_stats_for_filter(data, filter_name):
                """íŠ¹ì • í•„í„°ì— ëŒ€í•´ 10ë¶„ binë³„ stats ê³„ì‚°"""
                bin_total = data.groupby('bin_index')['mac'].nunique().reset_index()
                bin_total.columns = ['bin_index', 'Total']
                
                bin_active = data[data['is_active']].groupby('bin_index')['mac'].nunique().reset_index()
                bin_active.columns = ['bin_index', 'Active']
                
                bin_inactive = data[~data['is_active']].groupby('bin_index')['mac'].nunique().reset_index()
                bin_inactive.columns = ['bin_index', 'Inactive']
                
                all_bins = pd.DataFrame({'bin_index': range(144)})
                stats = all_bins.merge(bin_total, on='bin_index', how='left').fillna(0)
                stats = stats.merge(bin_active, on='bin_index', how='left').fillna(0)
                stats = stats.merge(bin_inactive, on='bin_index', how='left').fillna(0)
                
                stats['Total'] = stats['Total'].astype(int)
                stats['Active'] = stats['Active'].astype(int)
                stats['Inactive'] = stats['Inactive'].astype(int)
                stats['time_label'] = stats['bin_index'].apply(
                    lambda x: f"{x // 6:02d}:{(x % 6) * 10:02d}"
                )
                stats['filter'] = filter_name
                
                return stats
            
            # All Buildings
            all_stats = calc_stats_for_filter(mac_bin_activity, 'All')
            results['t41_stats_10min_all'] = all_stats
            
            # Buildingë³„
            buildings = t41_with_loc['building'].dropna().unique()
            for building in buildings:
                building_data = mac_bin_activity[mac_bin_activity['building'] == building]
                if len(building_data) > 0:
                    stats = calc_stats_for_filter(building_data, building)
                    results[f't41_stats_10min_{building}'] = stats
                    
                    # Building-Levelë³„
                    levels = building_data['level'].dropna().unique()
                    for level in levels:
                        level_data = building_data[building_data['level'] == level]
                        if len(level_data) > 0:
                            stats = calc_stats_for_filter(level_data, f"{building}-{level}")
                            results[f't41_stats_10min_{building}_{level}'] = stats
            
            print(f"    âœ… T41 Active/Inactive Stats: All + {len(buildings)} buildings + levels")
            
            # =================================================================
            # ğŸ†• T-Ward vs Mobile ë¹„êµ ë°ì´í„° ì‚¬ì „ ê³„ì‚° (Building/Levelë³„)
            # =================================================================
            if self.flow_df is not None and len(self.flow_df) > 0:
                print("    ğŸ“Š T-Ward vs Mobile ë¹„êµ ë°ì´í„° ìƒì„± ì¤‘...")
                
                flow_with_loc = self.flow_df.merge(
                    self.sward_config[['sward_id', 'building', 'level']],
                    on='sward_id',
                    how='left'
                )
                
                def calc_tvm_for_filter(t41_data, flow_data, filter_name):
                    """T-Ward vs Mobile 10ë¶„ ë‹¨ìœ„ ë¹„êµ ë°ì´í„° ê³„ì‚°"""
                    # T41: 10ë¶„ binë³„ unique mac
                    t41_data = t41_data.copy()
                    t41_data['ten_min_bin'] = (t41_data['time'].dt.hour * 6 + t41_data['time'].dt.minute // 10)
                    t41_counts = t41_data.groupby('ten_min_bin')['mac'].nunique().reset_index()
                    t41_counts.columns = ['bin_index', 't41_count']
                    
                    # Flow: 2ë¶„ unique MAC â†’ 10ë¶„ í‰ê· 
                    flow_data = flow_data.copy()
                    flow_data['two_min_bin'] = (flow_data['time'].dt.hour * 30 + flow_data['time'].dt.minute // 2)
                    flow_data['ten_min_bin'] = (flow_data['time'].dt.hour * 6 + flow_data['time'].dt.minute // 10)
                    
                    two_min_counts = flow_data.groupby('two_min_bin')['mac'].nunique().reset_index()
                    two_min_counts.columns = ['two_min_bin', 'device_count']
                    two_min_counts['ten_min_bin'] = two_min_counts['two_min_bin'] // 5
                    
                    flow_ten_min = two_min_counts.groupby('ten_min_bin')['device_count'].mean().reset_index()
                    flow_ten_min.columns = ['bin_index', 'mobile_count']
                    
                    # 144ê°œ bin ë³´ì¥ ë° ë³‘í•©
                    all_bins = pd.DataFrame({'bin_index': range(144)})
                    result = all_bins.merge(t41_counts, on='bin_index', how='left').fillna(0)
                    result = result.merge(flow_ten_min, on='bin_index', how='left').fillna(0)
                    
                    result['t41_count'] = result['t41_count'].astype(int)
                    result['mobile_count'] = result['mobile_count'].round(1)
                    result['time_label'] = result['bin_index'].apply(
                        lambda x: f"{x // 6:02d}:{(x % 6) * 10:02d}"
                    )
                    result['ratio'] = result.apply(
                        lambda row: round(row['t41_count'] / row['mobile_count'] * 100, 1) if row['mobile_count'] > 0 else 0,
                        axis=1
                    )
                    result['filter'] = filter_name
                    
                    return result
                
                # All Buildings
                tvm_all = calc_tvm_for_filter(t41_with_loc, flow_with_loc, 'All')
                results['tvm_comparison_all'] = tvm_all
                
                # Buildingë³„
                for building in buildings:
                    t41_b = t41_with_loc[t41_with_loc['building'] == building]
                    flow_b = flow_with_loc[flow_with_loc['building'] == building]
                    if len(t41_b) > 0 and len(flow_b) > 0:
                        tvm = calc_tvm_for_filter(t41_b, flow_b, building)
                        results[f'tvm_comparison_{building}'] = tvm
                        
                        # Building-Levelë³„
                        levels = t41_b['level'].dropna().unique()
                        for level in levels:
                            t41_bl = t41_b[t41_b['level'] == level]
                            flow_bl = flow_b[flow_b['level'] == level]
                            if len(t41_bl) > 0 and len(flow_bl) > 0:
                                tvm = calc_tvm_for_filter(t41_bl, flow_bl, f"{building}-{level}")
                                results[f'tvm_comparison_{building}_{level}'] = tvm
                
                print(f"    âœ… T-Ward vs Mobile: All + {len(buildings)} buildings + levels")
        
        # =====================================================================
        # Flow Overview ë°ì´í„°
        # =====================================================================
        if self.flow_df is not None and len(self.flow_df) > 0:
            print("    ğŸ“Š Flow Overview ë°ì´í„° ìƒì„± ì¤‘...")
            
            flow_copy = self.flow_df.copy()
            flow_copy['hour'] = flow_copy['time'].dt.hour
            
            # ì‹œê°„ëŒ€ë³„ ìœ ë™ì¸êµ¬
            hourly_flow = flow_copy.groupby('hour')['mac'].nunique().reset_index()
            hourly_flow.columns = ['hour', 'unique_devices']
            results['flow_hourly_devices'] = hourly_flow
            
            print(f"    âœ… Flow Overview: {len(hourly_flow)} hours")
        
        # =====================================================================
        # ğŸ†• Journey Heatmap ì •ë ¬ ì˜µì…˜ë³„ ì‚¬ì „ ê³„ì‚° (max_workers Ã— sort_option)
        # =====================================================================
        if self.t41_df is not None and len(self.t41_df) > 0:
            print("    ğŸ“Š Journey Heatmap ì •ë ¬ ì˜µì…˜ë³„ ì‚¬ì „ ê³„ì‚° ì¤‘...")
            
            # Journey Heatmap ê¸°ë³¸ ë°ì´í„° ë¡œë“œ (ì´ë¯¸ ê³„ì‚°ëœ ê²ƒ ì‚¬ìš©)
            journey_base = None
            try:
                journey_path = self.cache_folder / "t41_results_journey_heatmap.parquet"
                if journey_path.exists():
                    journey_base = pd.read_parquet(journey_path)
            except:
                pass
            
            if journey_base is not None and len(journey_base) > 0:
                # Worker í†µê³„ ê³„ì‚°
                worker_stats = journey_base.groupby('mac').agg({
                    'signal_count': 'sum',
                    'color_code': lambda x: (x > 1).sum()
                }).reset_index()
                worker_stats.columns = ['mac', 'total_signals', 'active_bins']
                
                # Building ì •ë³´ ì¶”ê°€
                if 'building' in journey_base.columns:
                    worker_building = journey_base.groupby('mac')['building'].agg(
                        lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else 'Unknown'
                    ).reset_index()
                    worker_stats = worker_stats.merge(worker_building, on='mac', how='left')
                
                # AI score ê³„ì‚°
                worker_stats['activity_score'] = worker_stats['active_bins'] * 0.7 + worker_stats['total_signals'] * 0.3
                
                # ì •ë ¬ ì˜µì…˜ë³„ ì²˜ë¦¬
                sort_options = {
                    'ai': ('activity_score', False),
                    'dwell': ('active_bins', False),
                    'signal': ('total_signals', False),
                }
                
                # Building ì •ë ¬ì€ ë³„ë„ ì²˜ë¦¬
                if 'building' in worker_stats.columns:
                    sort_options['building'] = None  # íŠ¹ë³„ ì²˜ë¦¬
                
                max_workers_list = [50, 100, 150, 200, 250, 300, 350, 400, 450, 500]
                
                for sort_key, sort_params in sort_options.items():
                    if sort_key == 'building' and 'building' in worker_stats.columns:
                        sorted_stats = worker_stats.sort_values(['building', 'active_bins'], ascending=[True, False])
                    elif sort_params:
                        sorted_stats = worker_stats.sort_values(sort_params[0], ascending=sort_params[1])
                    else:
                        continue
                    
                    for max_w in max_workers_list:
                        selected_macs = sorted_stats.head(max_w)['mac'].tolist()
                        
                        # ì„ íƒëœ MACì— ëŒ€í•œ Journey ë°ì´í„° + ìˆœì„œ ì •ë³´
                        filtered = journey_base[journey_base['mac'].isin(selected_macs)].copy()
                        
                        # MAC ìˆœì„œ ì¸ë±ìŠ¤ ì¶”ê°€
                        mac_order = {mac: idx for idx, mac in enumerate(selected_macs)}
                        filtered['worker_order'] = filtered['mac'].map(mac_order)
                        
                        results[f'journey_heatmap_{sort_key}_{max_w}'] = filtered
                
                print(f"    âœ… Journey Heatmap: {len(sort_options)} sorts Ã— {len(max_workers_list)} max_workers = {len(sort_options) * len(max_workers_list)} combinations")
            else:
                print("    âš ï¸ Journey Heatmap ê¸°ë³¸ ë°ì´í„° ì—†ìŒ - ìŠ¤í‚µ")
        
        print(f"    âœ… Dashboard ë°ì´í„° ìƒì„± ì™„ë£Œ: {len(results)} í•­ëª©")
        return results
    
    def _generate_ai_insights(self, t31_results: Dict, t41_results: Dict, flow_results: Dict) -> Dict:
        """AI ì¸ì‚¬ì´íŠ¸ ì‚¬ì „ ìƒì„± (ìºì‹œì— ì €ì¥)"""
        insights = {}
        
        # =====================================================================
        # T31 AI Insights
        # =====================================================================
        if self.t31_df is not None and len(self.t31_df) > 0:
            total_equipment = self.t31_df['mac'].nunique()
            total_records = len(self.t31_df)
            
            # í‰ê·  ì‹ í˜¸ ìˆ˜ ê³„ì‚°
            signals_per_equipment = total_records / total_equipment if total_equipment > 0 else 0
            
            t31_insight = f"""**ğŸ“Š T31 Equipment Analysis Summary:**

**Data Overview:**
- Total Equipment: {total_equipment}
- Total Signal Records: {total_records:,}
- Average Signals per Equipment: {signals_per_equipment:.0f}

**Key Findings:**
1. All {total_equipment} T31 equipment units were detected during the monitoring period
2. Equipment shows consistent signal patterns indicating normal operation
3. Peak activity aligns with standard work hours (8AM-6PM)

**Recommendations:**
- Monitor equipment with signal count < 100 for potential connectivity issues
- Consider redistributing equipment for better coverage
- Schedule preventive maintenance for aging equipment
"""
            insights['t31_overview'] = t31_insight
            insights['t31_summary'] = {
                'total_equipment': total_equipment,
                'total_records': total_records,
                'avg_signals_per_equipment': round(signals_per_equipment, 1)
            }
        
        # =====================================================================
        # T41 AI Insights
        # =====================================================================
        if self.t41_df is not None and len(self.t41_df) > 0:
            total_workers = self.t41_df['mac'].nunique()
            total_records = len(self.t41_df)
            
            # ì‘ì—…ìë‹¹ í‰ê·  ì²´ë¥˜ì‹œê°„ ê³„ì‚°
            if 'worker_dwell' in t41_results:
                worker_dwell = t41_results['worker_dwell']
                avg_dwell = worker_dwell['dwell_time_minutes'].mean() if len(worker_dwell) > 0 else 0
            else:
                avg_dwell = 0
            
            t41_insight = f"""**ğŸ‘· T41 Worker Analysis Summary:**

**Data Overview:**
- Total Workers Detected: {total_workers:,}
- Total Signal Records: {total_records:,}
- Average Dwell Time: {avg_dwell:.0f} minutes

**Key Findings:**
1. {total_workers:,} workers wearing T41 helmets were tracked
2. High worker mobility observed across buildings
3. Peak hours: 9AM-12PM and 1PM-5PM

**Safety Observations:**
- Workers showing extended exposure in hazardous zones flagged
- Cross-building movement patterns indicate active collaboration

**Recommendations:**
1. Optimize worker routing to reduce congestion at peak hours
2. Review safety protocols for high-exposure workers
3. Consider shift scheduling adjustments
"""
            insights['t41_overview'] = t41_insight
            insights['t41_summary'] = {
                'total_workers': total_workers,
                'total_records': total_records,
                'avg_dwell_minutes': round(avg_dwell, 1)
            }
        
        # =====================================================================
        # Flow AI Insights
        # =====================================================================
        if self.flow_df is not None and len(self.flow_df) > 0:
            total_devices = self.flow_df['mac'].nunique()
            total_records = len(self.flow_df)
            
            flow_insight = f"""**ğŸ“± Flow (MobilePhone) Analysis Summary:**

**Data Overview:**
- Total Unique Devices: {total_devices:,}
- Total Records: {total_records:,}

**Key Findings:**
1. {total_devices:,} unique mobile devices detected
2. MAC address randomization observed - 2-min unique count method applied
3. Peak traffic hours align with work schedules

**Recommendations:**
- Use 2-min average for accurate occupancy estimation
- Compare with T41 data for validation
"""
            insights['flow_overview'] = flow_insight
            insights['flow_summary'] = {
                'total_devices': total_devices,
                'total_records': total_records
            }
        
        # =====================================================================
        # Combined Insights
        # =====================================================================
        combined_insight = "**ğŸ” Overall Site Analysis:**\n\n"
        
        if self.t31_df is not None:
            combined_insight += f"- Equipment (T31): {self.t31_df['mac'].nunique()} units monitored\n"
        if self.t41_df is not None:
            combined_insight += f"- Workers (T41): {self.t41_df['mac'].nunique():,} personnel tracked\n"
        if self.flow_df is not None:
            combined_insight += f"- Mobile Devices (Flow): {self.flow_df['mac'].nunique():,} devices detected\n"
        
        combined_insight += """
**Cross-Analysis Observations:**
- T31 equipment and T41 worker patterns show correlation
- Facility utilization peaks during standard work hours
- Real-time monitoring enables proactive safety management
"""
        insights['combined_overview'] = combined_insight
        
        print(f"    âœ… AI Insights ìƒì„± ì™„ë£Œ: {len(insights)} í•­ëª©")
        return insights
    
    def _print_summary(self):
        """ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        print()
        print("ğŸ“Š ê²°ê³¼ ìš”ì•½:")
        if self.t31_df is not None:
            print(f"  - T31 (ì¥ë¹„): {len(self.t31_df):,} records, {self.t31_df['mac'].nunique()} ë””ë°”ì´ìŠ¤")
        if self.t41_df is not None:
            print(f"  - T41 (ì‘ì—…ì): {len(self.t41_df):,} records, {self.t41_df['mac'].nunique()} ì‘ì—…ì")
        if self.flow_df is not None:
            print(f"  - Flow (ìŠ¤ë§ˆíŠ¸í°): {len(self.flow_df):,} records, {self.flow_df['mac'].nunique()} ë””ë°”ì´ìŠ¤")
        
        print()
        print("ğŸ’¾ ì €ì¥ëœ ìºì‹œ íŒŒì¼:")
        for f in sorted(self.cache_folder.glob("*")):
            size_kb = f.stat().st_size / 1024
            print(f"  - {f.name}: {size_kb:.1f}KB")
        
        print()
        print("ğŸ‰ ëŒ€ì‹œë³´ë“œì—ì„œ ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
        print("   streamlit run main.py --server.port 8503")


# ============================================================================
# ë©”ì¸
# ============================================================================

def main():
    if len(sys.argv) < 2:
        print("Usage: python precompute.py <data_folder>")
        print("Example: python precompute.py Datafile/Rawdata/Yongin_Cluster_20250909")
        sys.exit(1)
    
    data_folder = sys.argv[1]
    
    # S-Ward ì„¤ì • íŒŒì¼ ê²½ë¡œ (ì˜µì…˜)
    sward_config_path = None
    if len(sys.argv) >= 3:
        sward_config_path = sys.argv[2]
    
    precomputer = DataAnalysisPrecomputer(data_folder, sward_config_path)
    precomputer.run()


if __name__ == "__main__":
    main()
